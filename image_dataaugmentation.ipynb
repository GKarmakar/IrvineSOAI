{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_dataaugmentation",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "1HWqUwx2m5zN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "from __future__ import absolute_import"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uRLgvgdXqLhV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tDgooxkcqdo1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LIST_OF_LABELS = 'daisy,dandelion,roses,sunflowers,tulips'.split(',')\n",
        "HEIGHT = 299\n",
        "WIDTH = 299\n",
        "NUM_CHANNELS = 3\n",
        "NCLASSES = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ofX0Gk_q1vg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def linear_model(img, mode, hparams):\n",
        "  X = tf.reshape(img, [-1, HEIGHT*WIDTH*NUM_CHANNELS]) #Flatten\n",
        "  ylogits = tf.layers.dense(X,NCLASSES, activation=None)\n",
        "  return ylogits, NCLASSES\n",
        "\n",
        "def dnn_model(img, mode, hparams):\n",
        "  X = tf.reshape(img, [-1, HEIGHT*WIDTH*NUM_CHANNELS]) #Flatten\n",
        "  h1 = tf.layers.dense(X, 300, activation='tf.nn.relu')\n",
        "  h2 = tf.layers.dense(h1, 100, activation='tf.nn.relu')\n",
        "  h3 = tf.layers.dense(h2, 30, activation='tf.nn.relu')\n",
        "  ylogits = tf.layers.dense(h3, NCLASSES, activation=None)\n",
        "  \n",
        "  return ylogits, NCLASSES\n",
        "\n",
        "def dnn_dropout_model(img, mode, hparams):\n",
        "  dprob = hparams.get('dprob', 0.1)\n",
        "  \n",
        "  X = tf.reshape(img, [-1, HEIGHT*WIDTH*NUM_CHANNELS]) #Flatten\n",
        "  h1 = tf.layers.dense(X, 300, activation='tf.nn.relu')\n",
        "  h2 = tf.layers.dense(h1, 100, activation='tf.nn.relu')\n",
        "  h3 = tf.layers.dense(h2, 30, activation='tf.nn.relu')\n",
        "  h3d = tf.layers.dropout(h3, rate=dprob, training=(\n",
        "                              mode ==  tf.estimators.ModeKeys.TRAIN)) #only dropout when training\n",
        "  ylogits = tf.layers.dense(h3d, NCLASSES, activation=None)\n",
        "  return ylogits, NCLASSES\n",
        "\n",
        "def cnn_model(img, mode, hparams):\n",
        "  ksize1 = hparams.get('ksize', 5)\n",
        "  ksize2 = hparams.get('ksize2', 5)\n",
        "  nfil1 =  hparams.get('nfil1', 10)\n",
        "  nfil2 =  hparams.get('nfil2', 20)\n",
        "  dprob =  hparams.get('dprob', 0.25)\n",
        "  \n",
        "  c1 = tf.layers.conv2d(img, filters=nfil1,\n",
        "                        kernel_size=ksize1,\n",
        "                        strides=1,\n",
        "                        padding='same,\n",
        "                        activation=tf.nn.relu)\n",
        "  p1 = tf.layers.max_pooling2d(c1, pool_size=2, strides=2)\n",
        "\n",
        "  c2 = tf.layers.conv2d(img, filters=nfil2,\n",
        "                        kernel_size=ksize2,\n",
        "                        strides=1,\n",
        "                        padding='same,\n",
        "                        activation=tf.nn.relu)\n",
        "  p1 = tf.layers.max_pooling2d(c2, pool_size=2, strides=2)\n",
        "\n",
        "  outlen = p2.shape[1]*p2.shape[2]*p2.shape[3]\n",
        "  p2flat = tf.reshape(p2, [-1, outlen]) #Flatten\n",
        "  \n",
        "  #apply batch normalization\n",
        "  if hparams['batch_norm']:\n",
        "    h3 = tf.layers.dense(p2flat, 300, activation=None)\n",
        "    h3 = tf.layers.batch_normalization(\n",
        "          h3, training=(mode == tf.estimator.ModeKeys.TRAIN)) #Only batch norm in training\n",
        "    h3 = tf.layers.relu(h3)\n",
        "  else:\n",
        "    h3 = tf.layers.dense(p2flat, 300, activation=tf.nn.relu)\n",
        "    \n",
        "  #apply dropout\n",
        "  h3d = tf.layers.dropout(h3, rate=dropout, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
        "  ylogits = tf.layers.dense(p2flat, 300, activation=tf.nn.relu)\n",
        "  #apply batch normalization\n",
        "  if hparams['batch_norm']:\n",
        "    ylogits = tf.layers.batch_normalization(\n",
        "        ylogits, training = (mode = tf.estimator.ModeKeys.TRAIN))\n",
        "  return ylogits, NCLASSES"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}