{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_classification",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "gnks7zrLpKYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f166c28-b2eb-43f9-86af-a345b76a10a0"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "import os\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YbSIDv0n0d0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6e3bda3d-797d-4c84-82f6-1d4b982d72c9"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets('mnist/data', one_hot=True, reshape=False)\n",
        "print(mnist.train.images.shape)\n",
        "print(mnist.train.labels.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "(55000, 28, 28, 1)\n",
            "(55000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bbWvsu4gqGfG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "7e071422-1cbd-4676-b094-71ba2e5e777a"
      },
      "cell_type": "code",
      "source": [
        "HEIGHT = 28\n",
        "WIDTH = 28\n",
        "NCLASSES = 10\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "IMGNO = 10\n",
        "plt.imshow(mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH));"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0aeac30f98>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LBre1_-OpUos",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Using low-level tensorflow\n",
        "def linear_model(img, mode, hparams):\n",
        "  X = tf.reshape(img,[-1,HEIGHT*WIDTH]) #flatten\n",
        "  W = tf.get_variable(\"W\", [HEIGHT*WIDTH,NCLASSES], \n",
        "                      initializer = tf.truncated_normal_initializer(stddev=0.1,seed = 1))\n",
        "  b = tf.get_variable(\"b\",NCLASSES, initializer = tf.zeros_initializer)\n",
        "  ylogits = tf.matmul(X,W)+b\n",
        "  return ylogits, NCLASSES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "41Q2yr2h0U5X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Using tf.layers API\n",
        "def linear_model(img, mode, hparams):\n",
        "  X = tf.reshape(img,[-1,HEIGHT*WIDTH]) #flatten\n",
        "  ylogits = tf.layers.dense(X,NCLASSES,activation=None)\n",
        "  return ylogits, NCLASSES\n",
        "\n",
        "def dnn_model(img):\n",
        "  X =  tf.reshape(img, [-1, HEIGHT * WIDTH]) #flatten\n",
        "  h1 = tf.layers.dense(X, 300, activation=tf.nn.relu)\n",
        "  h2 = tf.layers.dense(h1, 100, activation=tf.nn.relu)\n",
        "  h3 = tf.layers.dense(h2, 30, activation=tf.nn.relu)\n",
        "  \n",
        "  ylogits = tf.layers.dense(h3, NCLASSES, activation=None)\n",
        "  \n",
        "  return ylogits, NCLASSES\n",
        "\n",
        "def dnn_dropout_model(img, mode, hparams):\n",
        "  dprob = hparams.get('dprob', 0.1)\n",
        "  X =  tf.reshape(img, [-1, HEIGHT * WIDTH]) #flatten\n",
        "  h1 = tf.layers.dense(X, 300, activation=tf.nn.relu)\n",
        "  h2 = tf.layers.dense(h1, 100, activation=tf.nn.relu)\n",
        "  h3 = tf.layers.dense(h2, 30, activation=tf.nn.relu)\n",
        "  h3d = tf.layers.dropout(h3, rate=dprob, training=(\n",
        "                          mode==tf.estimator.ModeKeys.TRAIN)) #Only dropout when training\n",
        "  ylogits = tf.layers.dense(h3d, NCLASSES, activation=None)\n",
        "  return ylogits, hparams\n",
        "\n",
        "def cnn_model(img, mode, hparams):\n",
        "  ksize1 = hparams.get('ksize1', 5)\n",
        "  ksize2 = hparams.get('ksize2', 5)\n",
        "  nfil1 = hparams.get('nfil1', 10)\n",
        "  nfil2 = hparams.get('nfil2', 20)\n",
        "  dprob = hparams.get('dprob', 0.25)\n",
        "  \n",
        "  c1 = tf.layers.conv2d(img, filters = nfil1,\n",
        "                        kernel_size=ksize1,\n",
        "                        strides = 1, #?X28X28X10\n",
        "                        padding = 'same',\n",
        "                        activation='relu')\n",
        "  p1 = tf.layers.max_pooling2d(c1, pool_size=2, strides=2) #?X14X14X10\n",
        "  c2 = tf.layers.conv2d(p1, filters=nfil2,\n",
        "                        kernel_size=ksize2,\n",
        "                        strides= 1,\n",
        "                        padding='same',\n",
        "                        activation='relu')\n",
        "  p2 = tf.layers.max_pooling2d(c2, pool_size=2, strides=2) #?X7X7X20\n",
        "  \n",
        "  outlen = p2.shape[1]*p2.shape[2]*p2.shape[3] #980\n",
        "  p2flat = tf.reshape(p2, [-1, outlen]) #flattened\n",
        "  \n",
        "  #apply batc normalization\n",
        "  if hparams['batch_norm']:\n",
        "    h3 = tf.layers.dense(p2flat, 300, activation=None)\n",
        "    h3 = tf.layers.batch_normalization(\n",
        "      h3, training=(mode==tf.estimator.ModeKeys.TRAIN)) #Only Batchnorm when training\n",
        "    h3 = tf.nn.relu(h3)\n",
        "  else:\n",
        "    h3 = tf.layers.dense(p2flat, 300, activation=tf.nn.relu)\n",
        "\n",
        "  #Apply dropout\n",
        "  h3d = tf.layers.dense(h3, NCLASSES, activation=None)\n",
        "  ylogits = tf.layers.dense(h3d, NCLASSES, activation=None)\n",
        "  \n",
        "  #Apply batch normalization once more\n",
        "  if hparams['batch_norm']:\n",
        "    ylogits = tf.layers.batch_normalization(\n",
        "                    ylogits, training=(mode==tf.estimator.ModeKeys.TRAIN))\n",
        "  return ylogits, hparams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yYtoTIYXrvhP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'image':mnist.train.images},\n",
        "    y=mnist.train.labels,\n",
        "    batch_size=100,\n",
        "    num_epochs=None,\n",
        "    shuffle=True,\n",
        "    queue_capacity=5000\n",
        "  )\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'image':mnist.test.images},\n",
        "    y=mnist.test.labels,\n",
        "    batch_size=100,\n",
        "    num_epochs=1,\n",
        "    shuffle=False,\n",
        "    queue_capacity=5000\n",
        "  )\n",
        "\n",
        "def serving_input_fn():\n",
        "  #input will be rank 3\n",
        "  feature_placeholders = {\n",
        "      'image': tf.placeholder(tf.float32, [None, HEIGHT, WIDTH])}\n",
        "  #But model function requires rank 4  \n",
        "  features = {\n",
        "      'image': tf.expand_dims(feature_placeholders['image'], -1)}\n",
        "  \n",
        "  return tf.estimator.export.ServingInputReceiver(features, \n",
        "                                                  feature_placeholders)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-kWBAiUswI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def image_classifier(features, labels, mode, params):\n",
        "  #ylogits, nclasses = linear_model(features['image'])\n",
        "  model_functions = {\n",
        "        'linear': linear_model,\n",
        "        'dnn': dnn_model,\n",
        "        'dnn_dropout': dnn_dropout_model,\n",
        "        'cnn': cnn_model}\n",
        "  model_function = model_functions[params['model']]\n",
        "  ylogits, n_classes = model_function(features['image'], mode, params)\n",
        "  \n",
        "  probabilities = tf.nn.softmax(ylogits)\n",
        "  classes = tf.cast(tf.argmax(probabilities, 1), tf.uint8)\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=ylogits, \n",
        "                                                                     labels=labels))\n",
        "    evalmetrics =  {'accuracy': tf.metrics.accuracy(classes, \n",
        "                                                    tf.argmax(labels, 1))}\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      train_op = tf.contrib.layers.optimize_loss(loss, tf.train.get_global_step(),\n",
        "                                                 learning_rate=params['learning_rate'], \n",
        "                                                               optimizer=\"Adam\")\n",
        "    else:\n",
        "      train_op = None\n",
        "  else:\n",
        "    loss = None\n",
        "    train_op = None\n",
        "    evalmetrics = None\n",
        " \n",
        "  return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions={\"probabilities\": probabilities, \"classes\": classes},\n",
        "        loss=loss,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops=evalmetrics,\n",
        "        export_outputs={'classes': tf.estimator.export.PredictOutput(\n",
        "            {\"probabilities\": probabilities, \n",
        "             \"classes\": classes})}\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aN09NDEDvsd2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(output_dir, hparams):\n",
        "  EVAL_INTERVAL = 60\n",
        "  estimator = tf.estimator.Estimator(model_fn = image_classifier,\n",
        "                                     params = hparams,\n",
        "                                     config=tf.estimator.RunConfig(\n",
        "                                         save_checkpoints_secs = EVAL_INTERVAL),\n",
        "                                     model_dir = output_dir)\n",
        "  train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn,\n",
        "                                    max_steps = hparams['train_steps'])\n",
        "  exporter = tf.estimator.LatestExporter('Servo', serving_input_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn,\n",
        "                                  steps = None,\n",
        "                                  exporters = exporter)\n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C471lLSGwlip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1346
        },
        "outputId": "8bd7e840-a6b6-428d-929a-d7258cd22a94"
      },
      "cell_type": "code",
      "source": [
        "OUTDIR='mnist/learned'\n",
        "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
        "\n",
        "hparams = {'model': 'cnn', \n",
        "           'batch_norm': 1,\n",
        "           'train_steps': 1000, \n",
        "           'learning_rate': 0.01}\n",
        "train_and_evaluate(OUTDIR, hparams)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'mnist/learned', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 60, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0aeecc7908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 60.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into mnist/learned/model.ckpt.\n",
            "INFO:tensorflow:loss = 3.0132554, step = 1\n",
            "INFO:tensorflow:global_step/sec: 8.47838\n",
            "INFO:tensorflow:loss = 0.1399934, step = 101 (11.798 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.61146\n",
            "INFO:tensorflow:loss = 0.102581196, step = 201 (11.611 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.59484\n",
            "INFO:tensorflow:loss = 0.058918785, step = 301 (11.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.5861\n",
            "INFO:tensorflow:loss = 0.111146376, step = 401 (11.648 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.61302\n",
            "INFO:tensorflow:loss = 0.07439198, step = 501 (11.610 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 513 into mnist/learned/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-13-00:06:54\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-513\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-13-00:07:00\n",
            "INFO:tensorflow:Saving dict for global step 513: accuracy = 0.9832, global_step = 513, loss = 0.054709382\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 513: mnist/learned/model.ckpt-513\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['classes', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-513\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: mnist/learned/export/Servo/temp-b'1536797220'/saved_model.pb\n",
            "INFO:tensorflow:global_step/sec: 5.52068\n",
            "INFO:tensorflow:loss = 0.05591869, step = 601 (18.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.65596\n",
            "INFO:tensorflow:loss = 0.06058064, step = 701 (11.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.63086\n",
            "INFO:tensorflow:loss = 0.06781502, step = 801 (11.586 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.65469\n",
            "INFO:tensorflow:loss = 0.040151447, step = 901 (11.555 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 976 into mnist/learned/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into mnist/learned/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-13-00:07:58\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-13-00:08:03\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9826, global_step = 1000, loss = 0.05878782\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: mnist/learned/model.ckpt-1000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['classes', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: mnist/learned/export/Servo/temp-b'1536797283'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.018915378.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n7Dkh_z-w7tP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}